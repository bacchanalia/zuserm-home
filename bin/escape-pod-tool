#!/usr/bin/perl
use strict;
use warnings;
use utf8;

my $url = 'https://en.wikipedia.org/wiki/List_of_Escape_Pod_episodes';
my $epDir = "$ENV{HOME}/escapepod";
my $mp3Dir = "$ENV{HOME}/Desktop/Music/books/Escape Pod";
my $csvDelim = ';';
my $forumUrl = "http://forum.escapeartists.net/index.php";

sub parseHtml($$);
sub htmlCacheFile($);
sub ensureHtmlCache($$);
sub checkHtmlCache($);
sub attemptPutHtmlCache($$);
sub attemptGunzip($);
sub readHtmlCache($);
sub getMP3Url($);
sub browserLoadArticle($);
sub readAttCache($);
sub writeAttCache($$);
sub extraInfo();
sub personLinks();
sub fmtPersonLink($$);
sub crawlForum();
sub downloadMP3File($$$$);
sub tagMP3File($$);
sub newMP3FileName($);

sub parseTableRow($);
sub padl($$);

sub csv($);
sub cell($);

sub arrEquals($$);
sub uniqArr(@);
sub run(@);

my $wikiPrefix = q@
List of episodes for the [[Escape Pod (podcast) | Escape Pod podcast]].

{| cellpadding="3" cellspacing="0" border="1" align="center" style="text-align:center" class="sortable"
|- style="background-color:#EFEFEF"
! '''#''' !! '''Name''' !! '''Author''' !! '''Reader''' !! '''Rating''' !! '''Time''' !! class="unsortable"|'''Discussion'''
@;
$wikiPrefix =~ s/^\n+//;
my $wikiSuffix = q@
|}

[[Category:Lists of podcast episodes|Escape Pod]]

<!--
|-
|  || [] || [[]] || [[]] ||  ||  || [ EPF]
-->
@;
$wikiSuffix =~ s/^\n+//;

my @ratings = (
  "G"     => 'OK for Kids',
  "PG"    => '10 and Up',
  "PG-13" => '13 and Up',
  "R"     => '17 and Up',
  "X"     => 'Erotica - NOT FOR KIDS',
);
my %ratingCategories = @ratings;
my @ratingOrder = @ratings[grep { !($_ & 1) } 0 .. $#ratings];

my $cmds = join "|", qw(
  --csv --url --wiki --mp3url --mp3filename --download --download-only --tag
);
my $usage = "Usage:
  $0 [$cmds [EPNUM EPNUM ..]]
    Fetch episode list from $url.
    Parse it, and print certain info.

    --csv {default if no args specified}
      Print episode info in CSV with delim=$csvDelim
    --url
      Print the article url for each EPNUM, using the links in the above url.
    --wiki
      Use article HTML pages and forums to approximate the wikipedia page
    --mp3url
      Print the download URL, parsed from the escape pod article HTML.
      HTML is fetched using curl/wget and cached in $epDir/html-cache/EPNUM.html
    --mp3filename
      Same as --mp3url, but only print the filename
    --download
      Get mp3url and download it with axel, then --tag it as below.
      Skip an EPNUM if the mp3filename
        or a file named \"###EPNUM TITLE.mp3\"
        is already present in the current dir.
    --download-only
      Same as --download, except do not --tag after downloading
    --tag
      Set tags and rename files.
      Gets mp3filename, assume it is in current dir.
      If mp3filename is not present, use the target name.

      Remove all id3 tags from the file, and set new tags.
      Uses 'id3v2' and 'mid3iconv'.
        title = \"TITLE\"
        author = \"AUTHOR [READER]\"
        tracknumber = \"EPNUM\"
        album = \"Escape Pod\"
      Rename the file from mp3filename => \"###EPNUM TITLE.mp3\"
      {with /s removed}

  EPNUM: escape pod episode number. if none are specified, all are used.
";

sub main(@){
  my $cmd = shift;
  $cmd = '--csv' if not defined $cmd;
  die $usage if $cmd !~ /^($cmds)$/;

  my @nums;
  for my $num(@_){
    die $usage if $num !~ /^(\d+)([ab]?)$/;
    my $epNum = sprintf "%03d%s", $1+0, $2;
    push @nums, $epNum;
  }
  die $usage if (grep {$_ !~ /^\d+[ab]?$/} @nums) > 0;

  my %okNums = map {$_ => 1} @nums;

  my $html = `wget -O - $url 2>/dev/null`;
  my @epNums;
  my @tableRows;
  while($html =~ /<tr>\s*<td>(\d+[ab]?)<\/td>.*?<\/tr>/gs){
    push @tableRows, $&;
    push @epNums, $1;
  }

  my $articleUrlCache = readAttCache 'article-url-cache';
  my $eps = {};
  for my $tableRow(@tableRows){
    my $ep = parseTableRow $tableRow;
    next if keys %okNums > 0 and not defined $okNums{$$ep{number}};
    my $epNum = $$ep{number};
    $$eps{$epNum} = $ep;
    $$articleUrlCache{$epNum} = $$ep{articleUrl};
  }
  writeAttCache 'article-url-cache', $articleUrlCache;
  my $exitCode = 0;

  if($cmd eq '--csv'){
    for my $epNum(sort keys %$eps){
      print csv($$eps{$epNum}) . "\n";
    }
  }elsif($cmd eq '--url'){
    for my $epNum(sort keys %$eps){
      print "$$eps{$epNum}{articleUrl}\n";
    }
  }elsif($cmd eq "--wiki"){
    if(@nums == 0){
      @nums = sort map {sprintf "%03d", $_} keys %$articleUrlCache;
    }
    print $wikiPrefix if @nums == keys %$articleUrlCache;
    for my $epNum(reverse @nums){
      my $articleUrl = $$articleUrlCache{$epNum};
      my $extraInfo = extraInfo();
      my $personLinks = personLinks();
      if(ensureHtmlCache $epNum, $articleUrl){
        my $ex = {};
        $ex = $$extraInfo{$epNum} if defined $$extraInfo{$epNum};
        my $info = parseHtml $epNum, $ex;

        my $rating = $$info{rating};
        $rating = "" if $rating eq "?";
        $rating =~ s/^\s*//;
        $rating =~ s/\s*$//;

        my $forum;
        if($$info{forum} ne "?"){
          $forum = "[$forumUrl?topic=$$info{forum} EPF]";
        }else{
          $forum = "none";
        }

        die "Malformed episode number: $epNum\n" if $epNum !~ /^(\d+)([ab]?)$/;
        my $num = sprintf "%d%s", $1+0, $2;

        my $note = '';
        $note = " $$ex{note}" if defined $$ex{note};
        my $fmt = ''
          . "|-\n| " . ($num)
          . " || [$articleUrl $$info{title}]$note"
          . " || " . fmtPersonLink($$info{author}, $personLinks)
          . " || " . fmtPersonLink($$info{reader}, $personLinks)
          . " || $rating"
          . " || $$info{duration}"
          . " || $forum"
          . "\n"
          ;
        $fmt =~ s/&#8217;/'/g;
        $fmt =~ s/&amp;/&/g;
        print $fmt;
      }else{
        print STDERR "   ERROR: $epNum\n";
      }
    }
    print $wikiSuffix if @nums == keys %$articleUrlCache;
  }elsif($cmd =~ /^(--mp3url|--mp3filename|--download|--download-only|--tag)/){
    for my $epNum(sort keys %$eps){
      if(ensureHtmlCache $epNum, $$eps{$epNum}{articleUrl}){
        my $mp3Url = getMP3Url $epNum;
        my $mp3FileName = $1 if $mp3Url =~ /([^\/]*\.mp3)$/;
        if($cmd eq '--mp3url'){
          print "$mp3Url\n";
        }elsif($cmd eq '--mp3filename'){
          print "$mp3FileName\n";
        }elsif($cmd eq '--download'){
          downloadMP3File($mp3Url, $mp3FileName, $$eps{$epNum}, 1);
        }elsif($cmd eq '--download-only'){
          downloadMP3File($mp3Url, $mp3FileName, $$eps{$epNum}, 0);
        }elsif($cmd eq '--tag'){
          tagMP3File($mp3FileName, $$eps{$epNum});
        }
      }else{
        print "   ERROR: $epNum\n";
        $exitCode = 1;
      }
    }
  }
  exit $exitCode;
}

sub parseHtml($$){
  my ($epNum, $ex) = @_;
  my $html = readHtmlCache $epNum;

  my $info = {};

  my @atts = qw(title author reader rating duration forum);

  my $mp3 = `ls "$mp3Dir"/$epNum*.mp3 2>/dev/null`;
  chomp $mp3;

  my $b = "(?:<\\/?\\s*(?:b|strong)[^>]*>)";
  my $span = "(?:<\\/?\\s*span[^>]*>)";
  my $ws = "[ \\t\\n]";
  my $readBy = "(?:narrated|read)$ws+(?:and produced )?by:?$ws+";

  my $isFlash = $html =~ /<title>.*Flash.*<\/title>/i;

  $html =~ s/\xa0/ /g;
  $html =~ s/\xc2/ /g;
  $html =~ s/&nbsp;/ /g;
  $html =~ s/&#160;/ /g;
  $html =~ s/Â/ /g;

  my $htmlNoMeta = $html;
  $htmlNoMeta =~ s/<meta$ws*[^>]*>//g;

  if(defined $$ex{title}){
    $$info{title} = $$ex{title};
  }elsif($html =~ /<title>(.*)<\/title>/i){
    my $title = $1;
    utf8::decode $title;
    $title =~ s/[:\.\-]\s*Escape\s*Pod\s*//g;
    $title =~ s/^\s*(EP|Escape\s*Pod|Episode)\s*\d+[ab]?[:\-]?//i;
    $title =~ s/^\s*//;
    $title =~ s/\s*$//;
    $title =~ s/&#039;/'/g;
    $title =~ s/&amp;/&/g;
    $title =~ s/’/'/g;
    $title =~ s/“/"/g;
    $title =~ s/”/"/g;
    $title =~ s/&quot;/"/g;
    $title =~ s/^\s*-\s*//g;
    utf8::encode $title;
    $$info{title} = $title;
  }

  if(not $isFlash){
    if(defined $$ex{author}){
      $$info{author} = $$ex{author};
    }elsif($htmlNoMeta =~ />by$ws*:?\s*$span?$b?(?:<a [^>]*>)?$b?([^<(]+)/i){
      $$info{author} = $1;
    }
  }else{
    my @authors;
    if(@authors == 0){
      @authors = $htmlNoMeta =~ /$b$ws*by$ws+([^<(]*)$b/gi;
    }
    if(@authors == 0){
      @authors = $htmlNoMeta =~ /$b$ws*by$ws+([^<(]*)</gi;
    }
    if(@authors == 0){
      @authors = $htmlNoMeta =~ /<\/a>,$ws*by$ws+([^<(]*)</gi;
    }
    if(@authors == 0){
      @authors = $htmlNoMeta =~ /(?<!narrated)$ws+by$ws+([^<(]*)</gi;
    }
    if(defined $$ex{author}){
      $$info{author} = $$ex{author};
    }else{
      $$info{author} = join ', ', @authors if @authors > 0;
    }
  }

  if(not $isFlash){
    if(defined $$ex{reader}){
      $$info{reader} = $$ex{reader};
    }elsif($htmlNoMeta =~ /$readBy$span?$b?(?:<a [^>]*>)?$b?([^<(]+)/i){
      $$info{reader} = $1;
    }
  }else{
    my @readers;
    if(@readers == 0){
      @readers = $htmlNoMeta =~ /$readBy(?:<a$ws+[^>]*>)?([^<]+)/gi;
    }
    if(@readers == 0){
      @readers = $htmlNoMeta =~ /\(narrator-? ([^)]+)\)/gi;
    }
    if(defined $$ex{reader}){
      $$info{reader} = $$ex{reader};
    }else{
      $$info{reader} = join ', ', @readers if @readers > 0;
    }
  }

  if(defined $$info{reader} and $$info{reader} =~ /^\s*the\s*author\s*$/i){
    $$info{reader} = $$info{author};
  }

  if(defined $$ex{rating}){
    $$info{rating} = $$ex{rating};
  }else{
    my $okRatings = join "|", reverse sort @ratingOrder;

    if(not defined $$info{rating}){
      if($html =~ /Rated\s*$b?\s*($okRatings)[ \t\n\.:\-<&]/){
        $$info{rating} = $1;
      }
    }

    if(not defined $$info{rating}){
      for my $rating(@ratingOrder){
        my $cat = $ratingCategories{$rating};
        if($html =~ /Rated\s*$b?\s*$cat[ \t\n\.:\-<&]/i){
          $$info{rating} = $rating;
        }
      }
    }

    if(not defined $$info{rating}){
      for my $rating(@ratingOrder){
        my $cat = $ratingCategories{$rating};
        die "$rating" if not defined $cat;
        if($html =~ /<meta property="article:section" content="$cat"\s*\/>/){
          $$info{rating} = $rating;
          last;
        }
      }
    }
  }

  my $durCache = readAttCache 'duration-cache';
  if(defined $$durCache{$epNum}){
    $$info{duration} = $$durCache{$epNum};
  }elsif($mp3 =~ /^(.*\/)?$epNum[^\/]*\.mp3$/ and -e $mp3){
    $mp3 =~ s/"/\\"/g;
    my $dur = `duration -n "$mp3"`;
    chomp $dur;
    if($dur =~ /^(\d+:)+\d+$/){
      $$info{duration} = $dur;
      $$durCache{$epNum} = $dur;
      writeAttCache 'duration-cache', $durCache;
    }
  }elsif($html =~ /<span[^>]*>\s*\[\s*((?:\d+:)+\d+)\s*\]\s*<\/span>/){
    $$info{duration} = $1;
  }

  my $forumCache = readAttCache 'forum-cache';
  if(defined $$ex{forum}){
    my $prev = $$forumCache{$epNum};
    if(not defined $prev or $prev ne $$ex{forum}){
      $$forumCache{$epNum} = $$ex{forum};
      writeAttCache 'forum-cache', $forumCache;
    }
  }
  if(not defined $$forumCache{$epNum}){
    print STDERR "updating forum cache\n";
    my $epArticles = crawlForum;
    for my $ep(sort keys %$epArticles){
      $$forumCache{$ep} = $$epArticles{$ep};
    }
    writeAttCache 'forum-cache', $forumCache;
  }
  if(defined $$forumCache{$epNum}){
    $$info{forum} = $$forumCache{$epNum};
  }

  for my $att(@atts){
    die "Missing '$att' for $epNum\n" if not defined $$info{$att};
  }

  return $info;
}

sub htmlCacheFile($){
  my $epNum = shift;
  return "$epDir/html-cache/$epNum.html";
}

sub ensureHtmlCache($$){
  my ($epNum, $articleUrl) = @_;
  my $attempts;
  return 1 if checkHtmlCache $epNum;

  $attempts = 10;
  while($attempts > 0 and not checkHtmlCache $epNum){
    $attempts--;
    attemptPutHtmlCache $epNum, $articleUrl;
  }
  if(not checkHtmlCache $epNum){
    browserLoadArticle $articleUrl;
  }
  $attempts = 10;
  while($attempts > 0 and not checkHtmlCache $epNum){
    $attempts--;
    attemptPutHtmlCache $epNum, $articleUrl;
  }

  return checkHtmlCache $epNum;
}

sub checkHtmlCache($){
  my $epNum = shift;
  my $cacheFile = htmlCacheFile $epNum;
  return 0 if not -e $cacheFile;
  my $html = `cat $cacheFile`;
  if($html =~ /href="([^"]*\.mp3)"/){
    return 1;
  }else{
    return 0;
  }
}

sub attemptPutHtmlCache($$){
  my ($epNum, $articleUrl) = @_;
  my $cacheFile = htmlCacheFile $epNum;

  run "curl -L \"$articleUrl\" -o \"$cacheFile\" 2>/dev/null";
  return 1 if checkHtmlCache $epNum;
  attemptGunzip($cacheFile);
  return 1 if checkHtmlCache $epNum;

  run "wget \"$articleUrl\" -O \"$cacheFile\" 2>/dev/null";
  return 1 if checkHtmlCache $epNum;
  attemptGunzip($cacheFile);
  return 1 if checkHtmlCache $epNum;

  run "rm", "-f", $cacheFile;
  return 0;
}

sub attemptGunzip($){
  my $file = shift;
  if(-e $file){
    run "mv", $file, "$file.gz";
    run "gunzip", "$file.gz";
  }
  if(-e "$file.gz"){
    run "rm", "-f", "$file.gz";
  }
}

sub readHtmlCache($){
  my $epNum = shift;
  my $cacheFile = htmlCacheFile $epNum;
  die "Missing html file for $epNum\n" if not checkHtmlCache $epNum;
  open FH, "< $cacheFile" or die "failed to read $cacheFile\n";
  my @lines = <FH>;
  close FH;
  return join '', @lines;
}

sub browserLoadArticle($){
  my $articleUrl = shift;
  system "uzbl $articleUrl >/dev/null 2>/dev/null &";
  sleep 5;
  system "pkill", "-f", "uzbl.*$articleUrl";
}

sub readAttCache($){
  my $name = shift;
  my $cacheFile = "$epDir/$name";
  my @lines = `cat $cacheFile 2>/dev/null`;
  my $cache = {};
  for my $line(@lines){
    if($line =~ /^(\d+[ab]?)\s+(.*)$/){
      $$cache{$1} = $2;
    }
  }
  return $cache;
}

sub writeAttCache($$){
  my ($name, $cache) = @_;
  my $cacheFile = "$epDir/$name";
  my $s = '';
  open FH, "> $cacheFile" or die "Couldnt write to $cacheFile\n";
  for my $epNum(sort {$a cmp $b} keys %$cache){
    die "Malformed episode number: $epNum\n" if $epNum !~ /^(\d+)([ab]?)$/;
    print FH sprintf "%03d%s %s\n", $1, $2, $$cache{$epNum};
  }
  close FH;
}

sub extraInfo(){
  my $file = "$epDir/extra-info";
  my $extraInfo = {};
  for my $line(`cat $file`){
    $line =~ s/#.*//;
    next if $line =~ /^\s*$/;
    if($line =~ /^(\d\d\d[ab]?) (title|author|reader|rating|forum|note) (.*)$/){
      $$extraInfo{$1}{$2} = $3;
    }else{
      die "malformed extra-info line: $line";
    }
  }
  return $extraInfo;
}

sub personLinks(){
  my $file = "$epDir/person-links";
  my $personLinks = {};
  for my $line(`cat $file`){
    $line =~ s/#.*//;
    next if $line =~ /^\s*$/;
    if($line =~ /^(.*)=>(.*)$/){
      my ($person, $link) = ($1, $2);
      chomp $link;
      $person =~ s/^\s*//;
      $person =~ s/\s*$//;
      $link =~ s/^\s*//;
      $link =~ s/\s*$//;
      $$personLinks{$person} = $link;
    }else{
      die "malformed person-links line: $line";
    }
  }
  return $personLinks;
}

sub fmtPersonLink($$){
  my ($person, $links) = @_;
  return $person if $person =~ /[\[\]]/;

  $person =~ s/\s*\.\s*Music\s*by\s*$//i;
  $person =~ s/&#8217;/'/g;
  $person =~ s/&amp;/&/g;
  my @people = split /(?:(?:\s+|,)and\s+)|(?:\s*[&,]\s*)/, $person;
  @people = grep {defined $_ and $_ =~ /\w/} @people;
  @people = grep {not $_ =~ /^\s*e-?mail[ :-]*$/} @people;
  @people = uniqArr @people;

  my @fmtPeople;
  for my $p(@people){
    $p =~ s/\s*\.?\s*$//;
    $p =~ s/ of the$//;
    $p =~ s/ of$//;
    $p =~ s/^author //;
    $p =~ s/^and //;
    $p =~ s/^\s*:\s*//;
    $p =~ s/;\s*courtesy\s*$//;
    $p =~ s/^\s*//;
    $p =~ s/\s*$//;
    my $link = $$links{$p};
    my $fmt;
    if(not defined $link){
      $fmt = "[[$p]]";
    }elsif($link =~ /^[ a-zA-Z0-9_\-]+$/){
      $fmt = "[[$p ($link)|$p]]";
    }else{
      $fmt = "[$link $p]";
    }
    push @fmtPeople, $fmt;
  }

  return join ", ", @fmtPeople;
}

sub crawlForum(){
  my $page = 0;
  my $epArticles = {};
  my $prevArticles = [];
  while($page < 50){
    my $board = "1." . (20*$page);
    my $url = "$forumUrl?board=$board";
    my $html = `curl -L \"$url\" 2>/dev/null`;
    my $pageArticles = [];
    while($html =~ /<a href="[^"]*topic=(\d+\.\d+)">EP(\d+[ab]?)[^*]/g){
      $$epArticles{$2} = $1;
      push @$pageArticles, $2;
    }
    print "@$pageArticles\n";
    if(arrEquals $pageArticles, $prevArticles){
      print "REPEAT AT PAGE $page\n";
      last;
    }
    $prevArticles = $pageArticles;
    $page++;
  }
  return $epArticles;
}

sub getMP3Url($){
  my $epNum = shift;
  my $html = readHtmlCache $epNum;
  if($html !~ /href="([^"]*\.mp3)"/){
    die "Could not read mp3 url for $epNum\n";
  }
  return $1;
}

sub downloadMP3File($$$$){
  my ($mp3Url, $mp3FileName, $ep, $tagFile) = @_;
  my $newFileName = newMP3FileName $ep;
  if(-e $mp3FileName or -e $newFileName){
    print "  skipping $$ep{number}..\n";
  }else{
    run "axel", $mp3Url;
    tagMP3File $mp3FileName, $ep if $tagFile;
  }
}
sub tagMP3File($$){
  my ($mp3FileName, $ep) = @_;
  my $oldFileName = $mp3FileName;
  my $newFileName = newMP3FileName $ep;

  if(not -e $oldFileName and not -e $newFileName){
    print "   ERROR: missing $oldFileName or $newFileName\n";
    return;
  }
  $oldFileName = $newFileName if not -e $oldFileName;

  run "id3v2", "--delete-all", $oldFileName;

  my $num = 0;
  $num += $1 if $$ep{number} =~ /(\d+)/;

  run "id3v2",
    "--TIT2", $$ep{title},
    "--TPE1", $$ep{author},
    "--TPE2", $$ep{reader},
    "--TRCK", $num,
    "--TALB", "Escape Pod",
    "--TYER", $$ep{date},
    $oldFileName;

  run "mid3iconv", $oldFileName;

  if($oldFileName ne $newFileName){
    run "mv", "--no-clobber", $oldFileName, $newFileName;
  }
}
sub newMP3FileName($){
  my $ep = shift;
  my $newFileName = "$$ep{number} $$ep{title}.mp3";
  $newFileName =~ s/\//_/g;
  return $newFileName;
}

sub parseTableRow($){
  my $tr = shift;

  $tr =~ /href="(http:\/\/escapepod.org\/(\d+\/\d+\/\d+)\/[^"]*)"/;
  my $articleUrl = $1;
  my $date = $2;

  $tr =~ s/<sup.*?<\/sup>//gsxi;
  $tr =~ s/\n/ /g;
  $tr =~ s/<a [^<>]* >  \s*(.*?)\s*  < \s* \/ \s* a \s* >/$1/gsxi;
  $tr =~ s/\s*<td [^<>]* >  \s*(.*?)\s*  < \s* \/ \s* td \s* >\s*/<>$1/gsxi;
  $tr =~ s/^\s*<tr>\s*<>(.*)<>\s*(EPF|none)\s*<\/tr>\s*$/$1/;
  if($tr =~ /^(\d+)([ab]?)<>([^<]*)<>([^<]*)<>([^<]*)<>([^<]*)<>([^<]*)$/){
    return {
      number => padl(3, $1) . $2,
      title => $3,
      author => $4,
      reader => $5,
      rating => $6,
      duration => $7,
      articleUrl => $articleUrl,
      date => $date,
    };
  }else{
    die "fucked up episode: $tr\n";
  }
}
sub padl($$){
  my ($len, $n) = @_;
  return ('0'x($len - length $n)) . $n;
}


sub csv($){
  my $ep = shift;
  my @cols = (
    cell $$ep{number},
    cell $$ep{title},
    cell $$ep{author},
    cell $$ep{reader},
    cell $$ep{date},
    cell $$ep{articleUrl},
  );
  return join ($csvDelim, @cols);
}
sub cell($){
  my $cell = shift;
  $cell =~ s/\&amp;/\&/g;
  if($cell =~ /\Q$csvDelim\E/ or $cell =~ /\Q"\E/){
    $cell =~ s/"/""/g;
    $cell = "\"$cell\"";
    return $cell;
  }else{
    return $cell;
  }
}

sub uniqArr(@){
  my %seen;
  my @newArr;
  for my $elem(@_){
    push @newArr, $elem if not defined $seen{$elem};
    $seen{$elem} = 1;
  }
  return @newArr;
}
sub arrEquals($$){
  my ($arr1, $arr2) = @_;
  return 0 if not defined $arr1 or not defined $arr2;
  return 0 if @$arr1 != @$arr2;
  for(my $i=0; $i<@$arr1; $i++){
    return 0 if $$arr1[$i] ne $$arr2[$i];
  }
  return 1;
}

sub run(@){
  print "@_\n";
  system @_;
  die "error running @_\n" if $? != 0;
}

&main(@ARGV);
